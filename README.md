# Image Captioning

## Overview

This project leverages Hugging Face Transformers, particularly the Vision Transformer (ViT), to perform image captioning. The project aims to use computer vision and natural language processing techniques to generate descriptive captions for images.

## Key Objectives

- **Image Analysis:** Utilize the Vision Transformer model to extract features from images.
- **Natural Language Generation:** Employ AutoTokenizer for text generation to create descriptive image captions.
- **Deployment:** Create an interface using Streamlit to generate captions for user-provided images.


## Getting Started
To run the app,

1. Clone the repository
2. Move to the cloned folder in the terminal
3. Install all the dependencies by running the command

``` pip install -r requirements.txt ```

4. To run the application, type
``` streamlit run app.py ```

5. The application will open on the URL **localhost:8501**

## Acknowledgements
This project was possible due to open-source contributions and resources available on HuggingFace.
